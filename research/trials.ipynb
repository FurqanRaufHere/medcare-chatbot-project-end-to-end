{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41d6a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56da5d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Medical Bot\\\\End-to-End-Medical-Chatbot---Generative-AI\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d2c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6abf360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Medical Bot\\\\End-to-End-Medical-Chatbot---Generative-AI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea32d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install langchain module\n",
    "%pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e636c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9489d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract text from a PDF file\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78762ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data= 'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53d525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490c0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the text into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    texts_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return texts_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93a74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks:  5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of text chunks: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d2bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def79c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04d9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Embeddings from HuggingFace\n",
    "def download_huggingface_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451af984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WALEED TRADER\\AppData\\Local\\Temp\\ipykernel_8236\\2489607415.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "g:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_huggingface_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ea57fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of query results:  384\n"
     ]
    }
   ],
   "source": [
    "query_results = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length of query results: \", len(query_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceaf79f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03447727486491203,\n",
       " 0.03102317824959755,\n",
       " 0.006734970025718212,\n",
       " 0.026108985766768456,\n",
       " -0.03936202451586723,\n",
       " -0.16030244529247284,\n",
       " 0.06692401319742203,\n",
       " -0.006441489793360233,\n",
       " -0.0474504791200161,\n",
       " 0.014758856035768986,\n",
       " 0.07087527960538864,\n",
       " 0.05552763119339943,\n",
       " 0.019193334504961967,\n",
       " -0.026251312345266342,\n",
       " -0.01010954286903143,\n",
       " -0.02694045566022396,\n",
       " 0.022307461127638817,\n",
       " -0.022226648405194283,\n",
       " -0.14969263970851898,\n",
       " -0.017493007704615593,\n",
       " 0.00767625542357564,\n",
       " 0.05435224249958992,\n",
       " 0.0032543970737606287,\n",
       " 0.031725890934467316,\n",
       " -0.0846213847398758,\n",
       " -0.02940601296722889,\n",
       " 0.05159561336040497,\n",
       " 0.04812406003475189,\n",
       " -0.0033148222137242556,\n",
       " -0.058279167860746384,\n",
       " 0.04196927323937416,\n",
       " 0.022210685536265373,\n",
       " 0.1281888335943222,\n",
       " -0.022338971495628357,\n",
       " -0.011656315997242928,\n",
       " 0.06292839348316193,\n",
       " -0.032876335084438324,\n",
       " -0.09122604131698608,\n",
       " -0.031175347045063972,\n",
       " 0.0526994913816452,\n",
       " 0.04703482985496521,\n",
       " -0.08420311659574509,\n",
       " -0.030056199058890343,\n",
       " -0.02074483036994934,\n",
       " 0.009517835453152657,\n",
       " -0.0037217906210571527,\n",
       " 0.007343285251408815,\n",
       " 0.03932438790798187,\n",
       " 0.0932740643620491,\n",
       " -0.003788596484810114,\n",
       " -0.052742067724466324,\n",
       " -0.05805816128849983,\n",
       " -0.006864361464977264,\n",
       " 0.005283191800117493,\n",
       " 0.0828929990530014,\n",
       " 0.019362755119800568,\n",
       " 0.0062844837084412575,\n",
       " -0.010330787859857082,\n",
       " 0.009032378904521465,\n",
       " -0.037683695554733276,\n",
       " -0.04520607739686966,\n",
       " 0.024016305804252625,\n",
       " -0.006944137159734964,\n",
       " 0.013491630554199219,\n",
       " 0.10005494207143784,\n",
       " -0.07168391346931458,\n",
       " -0.021695120260119438,\n",
       " 0.031618405133485794,\n",
       " -0.051634665578603745,\n",
       " -0.08224772661924362,\n",
       " -0.06569333374500275,\n",
       " -0.00989533495157957,\n",
       " 0.005816374905407429,\n",
       " 0.07355456054210663,\n",
       " -0.034050311893224716,\n",
       " 0.0248861201107502,\n",
       " 0.014488042332231998,\n",
       " 0.02645738422870636,\n",
       " 0.009656722657382488,\n",
       " 0.0302172489464283,\n",
       " 0.05280393362045288,\n",
       " -0.07535984367132187,\n",
       " 0.009897145442664623,\n",
       " 0.029836809262633324,\n",
       " 0.01755557768046856,\n",
       " 0.023091984912753105,\n",
       " 0.001933806692250073,\n",
       " 0.0014002545503899455,\n",
       " -0.04717595875263214,\n",
       " -0.011194315738976002,\n",
       " -0.11420144140720367,\n",
       " -0.019811924546957016,\n",
       " 0.040266189724206924,\n",
       " 0.0021929906215518713,\n",
       " -0.07979220896959305,\n",
       " -0.02538231760263443,\n",
       " 0.09448299556970596,\n",
       " -0.02898104302585125,\n",
       " -0.14500252902507782,\n",
       " 0.23097744584083557,\n",
       " 0.027731187641620636,\n",
       " 0.03211146965622902,\n",
       " 0.03106505796313286,\n",
       " 0.04283284768462181,\n",
       " 0.06423777341842651,\n",
       " 0.03216316178441048,\n",
       " -0.004876770544797182,\n",
       " 0.055699463933706284,\n",
       " -0.03753238171339035,\n",
       " -0.02150554023683071,\n",
       " -0.028342634439468384,\n",
       " -0.028846951201558113,\n",
       " 0.0383530892431736,\n",
       " -0.017468664795160294,\n",
       " 0.052485305815935135,\n",
       " -0.07487601786851883,\n",
       " -0.03125976398587227,\n",
       " 0.021841565147042274,\n",
       " -0.03989570587873459,\n",
       " -0.008587091229856014,\n",
       " 0.026956576853990555,\n",
       " -0.04849553853273392,\n",
       " 0.011469882912933826,\n",
       " 0.02961820363998413,\n",
       " -0.02057218924164772,\n",
       " 0.013103843666613102,\n",
       " 0.028833510354161263,\n",
       " -3.1941990848222185e-33,\n",
       " 0.06478213518857956,\n",
       " -0.018130183219909668,\n",
       " 0.051789961755275726,\n",
       " 0.12198275327682495,\n",
       " 0.028780106455087662,\n",
       " 0.008721951395273209,\n",
       " -0.07052119821310043,\n",
       " -0.016907278448343277,\n",
       " 0.04073973000049591,\n",
       " 0.042116157710552216,\n",
       " 0.025447236374020576,\n",
       " 0.03574628755450249,\n",
       " -0.04914471507072449,\n",
       " 0.0021290204022079706,\n",
       " -0.015546582639217377,\n",
       " 0.050730545073747635,\n",
       " -0.0481853261590004,\n",
       " 0.03588061034679413,\n",
       " -0.0040670474991202354,\n",
       " 0.10172472149133682,\n",
       " -0.05597002059221268,\n",
       " -0.010681048966944218,\n",
       " 0.01123578567057848,\n",
       " 0.09068653732538223,\n",
       " 0.004234451334923506,\n",
       " 0.035138655453920364,\n",
       " -0.009702847339212894,\n",
       " -0.09386517852544785,\n",
       " 0.0928555428981781,\n",
       " 0.008004927076399326,\n",
       " -0.007705425377935171,\n",
       " -0.05208674445748329,\n",
       " -0.012587991543114185,\n",
       " 0.0032669377978891134,\n",
       " 0.006013509817421436,\n",
       " 0.007581559009850025,\n",
       " 0.01051718182861805,\n",
       " -0.08634556829929352,\n",
       " -0.06987880170345306,\n",
       " -0.0025338928680866957,\n",
       " -0.09097658842802048,\n",
       " 0.04688733071088791,\n",
       " 0.052076540887355804,\n",
       " 0.007193844299763441,\n",
       " 0.010903622955083847,\n",
       " -0.0052295587956905365,\n",
       " 0.013937311246991158,\n",
       " 0.021968349814414978,\n",
       " 0.03420866280794144,\n",
       " 0.060224682092666626,\n",
       " 0.00011665470083244145,\n",
       " 0.014731976203620434,\n",
       " -0.07008926570415497,\n",
       " 0.028499048203229904,\n",
       " -0.02760172076523304,\n",
       " 0.010768445208668709,\n",
       " 0.034830961376428604,\n",
       " -0.02248787134885788,\n",
       " 0.009769017808139324,\n",
       " 0.07722785323858261,\n",
       " 0.021588314324617386,\n",
       " 0.11495620757341385,\n",
       " -0.0680011734366417,\n",
       " 0.02376098558306694,\n",
       " -0.0159839428961277,\n",
       " -0.0178269911557436,\n",
       " 0.06439495831727982,\n",
       " 0.032025739550590515,\n",
       " 0.05027025192975998,\n",
       " -0.005913770757615566,\n",
       " -0.03370805084705353,\n",
       " 0.017840256914496422,\n",
       " 0.016573317348957062,\n",
       " 0.06329657882452011,\n",
       " 0.03467721864581108,\n",
       " 0.046473488211631775,\n",
       " 0.09790610522031784,\n",
       " -0.00663550291210413,\n",
       " 0.02520712837576866,\n",
       " -0.07798824459314346,\n",
       " 0.0169264767318964,\n",
       " -0.000945797364693135,\n",
       " 0.022471921518445015,\n",
       " -0.038253191858530045,\n",
       " 0.09570474177598953,\n",
       " -0.005350803025066853,\n",
       " 0.010469110682606697,\n",
       " -0.11524055153131485,\n",
       " -0.013262521475553513,\n",
       " -0.010709455236792564,\n",
       " -0.08311725407838821,\n",
       " 0.07327353954315186,\n",
       " 0.04939225688576698,\n",
       " -0.008994322270154953,\n",
       " -0.09584552049636841,\n",
       " 3.3661485617505796e-33,\n",
       " 0.12493184208869934,\n",
       " 0.01934972032904625,\n",
       " -0.05822571739554405,\n",
       " -0.03598826378583908,\n",
       " -0.05074676498770714,\n",
       " -0.04566238448023796,\n",
       " -0.08260336518287659,\n",
       " 0.1481948047876358,\n",
       " -0.08842118829488754,\n",
       " 0.06027443706989288,\n",
       " 0.05103015899658203,\n",
       " 0.01030314713716507,\n",
       " 0.14121422171592712,\n",
       " 0.03081384487450123,\n",
       " 0.061033159494400024,\n",
       " -0.052851270884275436,\n",
       " 0.1366489678621292,\n",
       " 0.00918989721685648,\n",
       " -0.01732518896460533,\n",
       " -0.012848555110394955,\n",
       " -0.007995282299816608,\n",
       " -0.0509800985455513,\n",
       " -0.05235064774751663,\n",
       " 0.007593012880533934,\n",
       " -0.015166307799518108,\n",
       " 0.01696030981838703,\n",
       " 0.021270520985126495,\n",
       " 0.020558107644319534,\n",
       " -0.12002813816070557,\n",
       " 0.014461833983659744,\n",
       " 0.02675991877913475,\n",
       " 0.025330696254968643,\n",
       " -0.0427546352148056,\n",
       " 0.006768387276679277,\n",
       " -0.01445858459919691,\n",
       " 0.04526195675134659,\n",
       " -0.09147648513317108,\n",
       " -0.019439145922660828,\n",
       " -0.017833467572927475,\n",
       " -0.05491018295288086,\n",
       " -0.052641112357378006,\n",
       " -0.010459048673510551,\n",
       " -0.052016086876392365,\n",
       " 0.020891955122351646,\n",
       " -0.07997036725282669,\n",
       " -0.012111340649425983,\n",
       " -0.05773142725229263,\n",
       " 0.023178234696388245,\n",
       " -0.008031732402741909,\n",
       " -0.02598930336534977,\n",
       " -0.07995671033859253,\n",
       " -0.020728832110762596,\n",
       " 0.048817697912454605,\n",
       " -0.020389137789607048,\n",
       " -0.04917657747864723,\n",
       " 0.014159622602164745,\n",
       " -0.06362202018499374,\n",
       " -0.007807393092662096,\n",
       " 0.01643155701458454,\n",
       " -0.0256824791431427,\n",
       " 0.013381040655076504,\n",
       " 0.026248741894960403,\n",
       " 0.009978413581848145,\n",
       " 0.06322886794805527,\n",
       " 0.002672201255336404,\n",
       " -0.006582767236977816,\n",
       " 0.01663188263773918,\n",
       " 0.03236646577715874,\n",
       " 0.03794245794415474,\n",
       " -0.036376070231199265,\n",
       " -0.006910930387675762,\n",
       " 0.0001596928050275892,\n",
       " -0.0016335808904841542,\n",
       " -0.02727821283042431,\n",
       " -0.02803807333111763,\n",
       " 0.049681417644023895,\n",
       " -0.028867173939943314,\n",
       " -0.0024180689360946417,\n",
       " 0.014774908311665058,\n",
       " 0.009764534421265125,\n",
       " 0.005797638092190027,\n",
       " 0.013486160896718502,\n",
       " 0.0055678957141935825,\n",
       " 0.03722710534930229,\n",
       " 0.007232527248561382,\n",
       " 0.04015626385807991,\n",
       " 0.08150326460599899,\n",
       " 0.07199167460203171,\n",
       " -0.013056126423180103,\n",
       " -0.0428820475935936,\n",
       " -0.01101123820990324,\n",
       " 0.004897820297628641,\n",
       " -0.009229730814695358,\n",
       " 0.035191506147384644,\n",
       " -0.05103502422571182,\n",
       " -1.571437557856825e-08,\n",
       " -0.08862441033124924,\n",
       " 0.02390925958752632,\n",
       " -0.01623876392841339,\n",
       " 0.031700510531663895,\n",
       " 0.027284247800707817,\n",
       " 0.05246882885694504,\n",
       " -0.047070957720279694,\n",
       " -0.058847445994615555,\n",
       " -0.06320822983980179,\n",
       " 0.04088849574327469,\n",
       " 0.04982800409197807,\n",
       " 0.10655171424150467,\n",
       " -0.07450230419635773,\n",
       " -0.012495421804487705,\n",
       " 0.01837071217596531,\n",
       " 0.03947412595152855,\n",
       " -0.024797886610031128,\n",
       " 0.014516262337565422,\n",
       " -0.03706921637058258,\n",
       " 0.02001572772860527,\n",
       " -4.85817035951186e-05,\n",
       " 0.00986657664179802,\n",
       " 0.024838753044605255,\n",
       " -0.05245814099907875,\n",
       " 0.029314178973436356,\n",
       " -0.08719190955162048,\n",
       " -0.01449968758970499,\n",
       " 0.026019077748060226,\n",
       " -0.01874636672437191,\n",
       " -0.07620512694120407,\n",
       " 0.03504333272576332,\n",
       " 0.10363949835300446,\n",
       " -0.028050510212779045,\n",
       " 0.012718182988464832,\n",
       " -0.07632549107074738,\n",
       " -0.01865232177078724,\n",
       " 0.02497672848403454,\n",
       " 0.0814453512430191,\n",
       " 0.06875883787870407,\n",
       " -0.0640566498041153,\n",
       " -0.08389385789632797,\n",
       " 0.06136231869459152,\n",
       " -0.033545564860105515,\n",
       " -0.10615336894989014,\n",
       " -0.040080588310956955,\n",
       " 0.032530225813388824,\n",
       " 0.07662483304738998,\n",
       " -0.0730162113904953,\n",
       " 0.00033755265758372843,\n",
       " -0.040871646255254745,\n",
       " -0.0757884755730629,\n",
       " 0.027527665719389915,\n",
       " 0.07462543249130249,\n",
       " 0.01771726831793785,\n",
       " 0.09121846407651901,\n",
       " 0.11022016406059265,\n",
       " 0.0005697731394320726,\n",
       " 0.05146336182951927,\n",
       " -0.014551310800015926,\n",
       " 0.03323203697800636,\n",
       " 0.023792240768671036,\n",
       " -0.02288980595767498,\n",
       " 0.038937538862228394,\n",
       " 0.030206844210624695]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "742e1790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "902c1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "# OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72ba266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Install pinecone-client module\n",
    "# %pip install pinecone-client\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medcare-medical-chatbot\"\n",
    "\n",
    "# pc.create_index(\n",
    "#     name=index_name,\n",
    "#     dimension=384,  # The dimension of the embeddings\n",
    "#     metric=\"cosine\",\n",
    "#     spec=ServerlessSpec(\n",
    "#         cloud=\"aws\",\n",
    "#         region=\"us-east-1\",\n",
    "#     )\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "185c9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> pcsk_3TEqLd_KSZRqHyDw9phBUsmMLmUzzghGoK8k21oiY2zd9Ls7PKM4hPUU4ew9aUiP6JdQBT\n",
      "<class 'str'> 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\n"
     ]
    }
   ],
   "source": [
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "print(type(PINECONE_API_KEY), PINECONE_API_KEY)\n",
    "# print(type(OPENAI_API_KEY), OPENAI_API_KEY)\n",
    "print(type(GROQ_API_KEY), GROQ_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e179f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "# os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be921743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install langchain-pinecone if not already installed\n",
    "# %pip install langchain-pinecone\n",
    "\n",
    "# embed each chunk and upsert the embeddings into your pinecone index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98e200b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing Index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "#Embed each chunk and upsert the embeddings into your pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55432181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1fffaa37d90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3be6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84261c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrived_docs = retriever.invoke(\"What is the best way to treat a headache?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f992585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5876d89f-2238-42c2-8144-646e352ddf65', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 52.0, 'page_label': '53', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Gale Encyclopedia of Medicine Vol. 1 (A-B).pdf', 'total_pages': 637.0}, page_content='with the thumb or finger, for two minutes on each arm.\\n• For headaches, sinus congestion, and tension, locate the\\n“GB20” points at the base of the skull in the back of the\\nhead, just behind the bones in back of the ears. Disperse\\nthese points for two minutes with the fingers or thumbs.\\nAlso find the “yintang” point, which is in the middle of\\nthe forehead between the eyebrows. Disperse it with\\ngentle pressure for two minutes to clear the mind and to\\nrelieve headaches.\\nPrecautions'),\n",
       " Document(id='4b09b64d-928b-4bec-aca9-7ea2f7818351', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 52.0, 'page_label': '53', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Gale Encyclopedia of Medicine. Vol. 1. 2nd ed.pdf', 'total_pages': 637.0}, page_content='with the thumb or finger, for two minutes on each arm.\\n• For headaches, sinus congestion, and tension, locate the\\n“GB20” points at the base of the skull in the back of the\\nhead, just behind the bones in back of the ears. Disperse\\nthese points for two minutes with the fingers or thumbs.\\nAlso find the “yintang” point, which is in the middle of\\nthe forehead between the eyebrows. Disperse it with\\ngentle pressure for two minutes to clear the mind and to\\nrelieve headaches.\\nPrecautions'),\n",
       " Document(id='20f8a056-c549-4e90-874f-6f73fefca3fd', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 52.0, 'page_label': '53', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Gale Encyclopedia of Medicine Vol. 1 (A-B).pdf', 'total_pages': 637.0}, page_content='with the thumb or finger, for two minutes on each arm.\\n• For headaches, sinus congestion, and tension, locate the\\n“GB20” points at the base of the skull in the back of the\\nhead, just behind the bones in back of the ears. Disperse\\nthese points for two minutes with the fingers or thumbs.\\nAlso find the “yintang” point, which is in the middle of\\nthe forehead between the eyebrows. Disperse it with\\ngentle pressure for two minutes to clear the mind and to\\nrelieve headaches.\\nPrecautions')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595afcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WALEED TRADER\\AppData\\Local\\Temp\\ipykernel_9848\\2827040873.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.4, max_tokens=500)\n"
     ]
    }
   ],
   "source": [
    "# from langchain import OpenAI\n",
    "# llm = OpenAI(temperature=0.4, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"you are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Do not try to make up an answer. \"\n",
    "    \"Use three sentences maximum and keep the answer concise. \"\n",
    "    \"\\n\\n\"\n",
    "    \"Context: {context}\\n\\n\"    \n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf96b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50916330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms.openai import OpenAI\n",
    "# llm = OpenAI(temperature=0.4, max_tokens=500, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0.4,\n",
    "    model_name=\"llama3-70b-8192\",  # or \"llama3-8b-8192\"\n",
    "    groq_api_key=os.environ[\"GROQ_API_KEY\"]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "print(api_key)  # <-- Check if it's printing something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e590370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: **What is Acne?**\n",
      "\n",
      "Acne is a common skin condition that occurs when the pores on the skin become clogged with oil, dead skin cells, and bacteria. It can cause a range of symptoms, including:\n",
      "\n",
      "* Pimples or zits\n",
      "* Blackheads\n",
      "* Whiteheads\n",
      "* Redness and inflammation\n",
      "* Scarring\n",
      "\n",
      "Acne typically affects the face, but it can also appear on the neck, back, chest, and other areas of the body. It is most common during puberty, but it can occur at any age.\n",
      "\n",
      "**Causes of Acne:**\n",
      "\n",
      "There are several factors that can contribute to the development of acne, including:\n",
      "\n",
      "1. **Hormonal changes**: Fluctuations in hormone levels, such as during puberty, menstruation, or pregnancy, can lead to increased oil production and clogged pores.\n",
      "2. **Overproduction of sebum**: The skin's oil glands produce sebum, which can clog pores and lead to acne.\n",
      "3. **Dead skin cells**: When dead skin cells are not shed properly, they can accumulate and clog pores.\n",
      "4. **Bacterial growth**: A type of bacteria called Propionibacterium acnes (P. acnes) is naturally found on the skin and can contribute to the development of acne.\n",
      "5. **Genetics**: Family history can play a role in the development of acne.\n",
      "6. **Stress**: High levels of stress can increase the production of hormones, such as cortisol, which can contribute to acne.\n",
      "7. **Poor skin care**: Not washing the skin regularly or using the wrong skin care products can clog pores and lead to acne.\n",
      "\n",
      "**Types of Acne:**\n",
      "\n",
      "There are several types of acne, including:\n",
      "\n",
      "1. **Mild acne**: This type of acne is characterized by a few pimples or blackheads.\n",
      "2. **Moderate acne**: This type of acne is characterized by more frequent and widespread pimples, blackheads, and whiteheads.\n",
      "3. **Severe acne**: This type of acne is characterized by large, painful pimples, cysts, and scarring.\n",
      "4. **Cystic acne**: This type of acne is characterized by large, painful cysts that can leave scarring.\n",
      "\n",
      "**Treatment Options:**\n",
      "\n",
      "There are several treatment options available for acne, including:\n",
      "\n",
      "1. **Topical creams and gels**: These can help to reduce inflammation and kill bacteria.\n",
      "2. **Oral antibiotics**: These can help to reduce bacteria and inflammation.\n",
      "3. **Hormonal therapies**: These can help to regulate hormone levels and reduce oil production.\n",
      "4. **Blue light therapy**: This can help to kill bacteria and reduce inflammation.\n",
      "5. **Extraction**: This involves removing blackheads and whiteheads to help prevent scarring.\n",
      "\n",
      "It is essential to consult a dermatologist to determine the best course of treatment for acne. With the right treatment and proper skin care, it is possible to manage acne and prevent scarring.\n"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "# import os\n",
    "\n",
    "# client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# from anthropic import Anthropic\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# response = client.messages.create(\n",
    "#     model=\"claude-3-sonnet-20240229\",\n",
    "#     max_tokens=500,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"What is Acne?\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(response.content[0].text)\n",
    "\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from groq import Groq\n",
    "\n",
    "# load_dotenv()\n",
    "# client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"mixtral-8x7b\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"What is Acne?\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# groq_chatbot.py\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "# Load .env file and read API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please check your .env file.\")\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "# Chat request using Mixtral-8x7B\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",  # ✅ Correct model name\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"What is Acne?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Bot:\", response.choices[0].message.content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a7a43",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# response = rag_chain.invoke({\"input\": \"What is Acne?\"})\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# print(response['answer']) \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mrag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYour question here\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3034\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3033\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:511\u001b[39m, in \u001b[36mRunnableAssign.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m     **kwargs: Any,\n\u001b[32m    510\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1930\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1926\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1928\u001b[39m         output = cast(\n\u001b[32m   1929\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1930\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1933\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1935\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1936\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1937\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1938\u001b[39m         )\n\u001b[32m   1939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1940\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:497\u001b[39m, in \u001b[36mRunnableAssign._invoke\u001b[39m\u001b[34m(self, input, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m    492\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    496\u001b[39m     **\u001b[38;5;28minput\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     **\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    502\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3760\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3755\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3756\u001b[39m         futures = [\n\u001b[32m   3757\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3758\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3759\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3760\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3761\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3762\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3744\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input, config, key)\u001b[39m\n\u001b[32m   3738\u001b[39m child_config = patch_config(\n\u001b[32m   3739\u001b[39m     config,\n\u001b[32m   3740\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3741\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3742\u001b[39m )\n\u001b[32m   3743\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3746\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3747\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3748\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3034\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3033\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:387\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    378\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m     **kwargs: Any,\n\u001b[32m    384\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    385\u001b[39m     config = ensure_config(config)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    398\u001b[39m         .text\n\u001b[32m    399\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:764\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    757\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    761\u001b[39m     **kwargs: Any,\n\u001b[32m    762\u001b[39m ) -> LLMResult:\n\u001b[32m    763\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:971\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    957\u001b[39m     run_managers = [\n\u001b[32m    958\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    959\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    969\u001b[39m         )\n\u001b[32m    970\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    979\u001b[39m     run_managers = [\n\u001b[32m    980\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    981\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    989\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:790\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    780\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    781\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     **kwargs: Any,\n\u001b[32m    787\u001b[39m ) -> LLMResult:\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    789\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    794\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    798\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    799\u001b[39m         )\n\u001b[32m    800\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    801\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_community\\llms\\openai.py:463\u001b[39m, in \u001b[36mBaseOpenAI._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     choices.append(\n\u001b[32m    452\u001b[39m         {\n\u001b[32m    453\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: generation.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    460\u001b[39m         }\n\u001b[32m    461\u001b[39m     )\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     response = \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    467\u001b[39m         \u001b[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[32m    468\u001b[39m         \u001b[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[32m    469\u001b[39m         response = response.dict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\langchain_community\\llms\\openai.py:121\u001b[39m, in \u001b[36mcompletion_with_retry\u001b[39m\u001b[34m(llm, run_manager, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m retry_decorator = _create_retry_decorator(llm, run_manager=run_manager)\n\u001b[32m    125\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_completion_with_retry\u001b[39m(**kwargs: Any) -> Any:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\openai\\resources\\completions.py:541\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    514\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    540\u001b[39m ) -> Completion | Stream[Completion]:\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_of\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mecho\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msuffix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# response = rag_chain.invoke({\"input\": \"What is Acne?\"})\n",
    "# print(response['answer']) \n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"Your question here\"})\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedChat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
