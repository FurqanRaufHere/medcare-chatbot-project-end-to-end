{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56da5d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Medical Bot\\\\End-to-End-Medical-Chatbot---Generative-AI\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6abf360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Medical Bot\\\\End-to-End-Medical-Chatbot---Generative-AI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea32d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in g:\\medical bot\\end-to-end-medical-chatbot---generative-ai\\medchat\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install langchain module\n",
    "%pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e636c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9489d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract text from a PDF file\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78762ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data= 'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53d525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490c0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the text into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    texts_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return texts_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93a74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks:  5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of text chunks: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d2bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def79c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04d9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Embeddings from HuggingFace\n",
    "def download_huggingface_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451af984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WALEED TRADER\\AppData\\Local\\Temp\\ipykernel_13728\\2489607415.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "g:\\Medical Bot\\End-to-End-Medical-Chatbot---Generative-AI\\MedChat\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_huggingface_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ea57fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of query results:  384\n"
     ]
    }
   ],
   "source": [
    "query_results = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length of query results: \", len(query_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceaf79f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03447727486491203,\n",
       " 0.03102317824959755,\n",
       " 0.006734970025718212,\n",
       " 0.026108985766768456,\n",
       " -0.03936202451586723,\n",
       " -0.16030244529247284,\n",
       " 0.06692401319742203,\n",
       " -0.006441489793360233,\n",
       " -0.0474504791200161,\n",
       " 0.014758856035768986,\n",
       " 0.07087527960538864,\n",
       " 0.05552763119339943,\n",
       " 0.019193334504961967,\n",
       " -0.026251312345266342,\n",
       " -0.01010954286903143,\n",
       " -0.02694045566022396,\n",
       " 0.022307461127638817,\n",
       " -0.022226648405194283,\n",
       " -0.14969263970851898,\n",
       " -0.017493007704615593,\n",
       " 0.00767625542357564,\n",
       " 0.05435224249958992,\n",
       " 0.0032543970737606287,\n",
       " 0.031725890934467316,\n",
       " -0.0846213847398758,\n",
       " -0.02940601296722889,\n",
       " 0.05159561336040497,\n",
       " 0.04812406003475189,\n",
       " -0.0033148222137242556,\n",
       " -0.058279167860746384,\n",
       " 0.04196927323937416,\n",
       " 0.022210685536265373,\n",
       " 0.1281888335943222,\n",
       " -0.022338971495628357,\n",
       " -0.011656315997242928,\n",
       " 0.06292839348316193,\n",
       " -0.032876335084438324,\n",
       " -0.09122604131698608,\n",
       " -0.031175347045063972,\n",
       " 0.0526994913816452,\n",
       " 0.04703482985496521,\n",
       " -0.08420311659574509,\n",
       " -0.030056199058890343,\n",
       " -0.02074483036994934,\n",
       " 0.009517835453152657,\n",
       " -0.0037217906210571527,\n",
       " 0.007343285251408815,\n",
       " 0.03932438790798187,\n",
       " 0.0932740643620491,\n",
       " -0.003788596484810114,\n",
       " -0.052742067724466324,\n",
       " -0.05805816128849983,\n",
       " -0.006864361464977264,\n",
       " 0.005283191800117493,\n",
       " 0.0828929990530014,\n",
       " 0.019362755119800568,\n",
       " 0.0062844837084412575,\n",
       " -0.010330787859857082,\n",
       " 0.009032378904521465,\n",
       " -0.037683695554733276,\n",
       " -0.04520607739686966,\n",
       " 0.024016305804252625,\n",
       " -0.006944137159734964,\n",
       " 0.013491630554199219,\n",
       " 0.10005494207143784,\n",
       " -0.07168391346931458,\n",
       " -0.021695120260119438,\n",
       " 0.031618405133485794,\n",
       " -0.051634665578603745,\n",
       " -0.08224772661924362,\n",
       " -0.06569333374500275,\n",
       " -0.00989533495157957,\n",
       " 0.005816374905407429,\n",
       " 0.07355456054210663,\n",
       " -0.034050311893224716,\n",
       " 0.0248861201107502,\n",
       " 0.014488042332231998,\n",
       " 0.02645738422870636,\n",
       " 0.009656722657382488,\n",
       " 0.0302172489464283,\n",
       " 0.05280393362045288,\n",
       " -0.07535984367132187,\n",
       " 0.009897145442664623,\n",
       " 0.029836809262633324,\n",
       " 0.01755557768046856,\n",
       " 0.023091984912753105,\n",
       " 0.001933806692250073,\n",
       " 0.0014002545503899455,\n",
       " -0.04717595875263214,\n",
       " -0.011194315738976002,\n",
       " -0.11420144140720367,\n",
       " -0.019811924546957016,\n",
       " 0.040266189724206924,\n",
       " 0.0021929906215518713,\n",
       " -0.07979220896959305,\n",
       " -0.02538231760263443,\n",
       " 0.09448299556970596,\n",
       " -0.02898104302585125,\n",
       " -0.14500252902507782,\n",
       " 0.23097744584083557,\n",
       " 0.027731187641620636,\n",
       " 0.03211146965622902,\n",
       " 0.03106505796313286,\n",
       " 0.04283284768462181,\n",
       " 0.06423777341842651,\n",
       " 0.03216316178441048,\n",
       " -0.004876770544797182,\n",
       " 0.055699463933706284,\n",
       " -0.03753238171339035,\n",
       " -0.02150554023683071,\n",
       " -0.028342634439468384,\n",
       " -0.028846951201558113,\n",
       " 0.0383530892431736,\n",
       " -0.017468664795160294,\n",
       " 0.052485305815935135,\n",
       " -0.07487601786851883,\n",
       " -0.03125976398587227,\n",
       " 0.021841565147042274,\n",
       " -0.03989570587873459,\n",
       " -0.008587091229856014,\n",
       " 0.026956576853990555,\n",
       " -0.04849553853273392,\n",
       " 0.011469882912933826,\n",
       " 0.02961820363998413,\n",
       " -0.02057218924164772,\n",
       " 0.013103843666613102,\n",
       " 0.028833510354161263,\n",
       " -3.1941990848222185e-33,\n",
       " 0.06478213518857956,\n",
       " -0.018130183219909668,\n",
       " 0.051789961755275726,\n",
       " 0.12198275327682495,\n",
       " 0.028780106455087662,\n",
       " 0.008721951395273209,\n",
       " -0.07052119821310043,\n",
       " -0.016907278448343277,\n",
       " 0.04073973000049591,\n",
       " 0.042116157710552216,\n",
       " 0.025447236374020576,\n",
       " 0.03574628755450249,\n",
       " -0.04914471507072449,\n",
       " 0.0021290204022079706,\n",
       " -0.015546582639217377,\n",
       " 0.050730545073747635,\n",
       " -0.0481853261590004,\n",
       " 0.03588061034679413,\n",
       " -0.0040670474991202354,\n",
       " 0.10172472149133682,\n",
       " -0.05597002059221268,\n",
       " -0.010681048966944218,\n",
       " 0.01123578567057848,\n",
       " 0.09068653732538223,\n",
       " 0.004234451334923506,\n",
       " 0.035138655453920364,\n",
       " -0.009702847339212894,\n",
       " -0.09386517852544785,\n",
       " 0.0928555428981781,\n",
       " 0.008004927076399326,\n",
       " -0.007705425377935171,\n",
       " -0.05208674445748329,\n",
       " -0.012587991543114185,\n",
       " 0.0032669377978891134,\n",
       " 0.006013509817421436,\n",
       " 0.007581559009850025,\n",
       " 0.01051718182861805,\n",
       " -0.08634556829929352,\n",
       " -0.06987880170345306,\n",
       " -0.0025338928680866957,\n",
       " -0.09097658842802048,\n",
       " 0.04688733071088791,\n",
       " 0.052076540887355804,\n",
       " 0.007193844299763441,\n",
       " 0.010903622955083847,\n",
       " -0.0052295587956905365,\n",
       " 0.013937311246991158,\n",
       " 0.021968349814414978,\n",
       " 0.03420866280794144,\n",
       " 0.060224682092666626,\n",
       " 0.00011665470083244145,\n",
       " 0.014731976203620434,\n",
       " -0.07008926570415497,\n",
       " 0.028499048203229904,\n",
       " -0.02760172076523304,\n",
       " 0.010768445208668709,\n",
       " 0.034830961376428604,\n",
       " -0.02248787134885788,\n",
       " 0.009769017808139324,\n",
       " 0.07722785323858261,\n",
       " 0.021588314324617386,\n",
       " 0.11495620757341385,\n",
       " -0.0680011734366417,\n",
       " 0.02376098558306694,\n",
       " -0.0159839428961277,\n",
       " -0.0178269911557436,\n",
       " 0.06439495831727982,\n",
       " 0.032025739550590515,\n",
       " 0.05027025192975998,\n",
       " -0.005913770757615566,\n",
       " -0.03370805084705353,\n",
       " 0.017840256914496422,\n",
       " 0.016573317348957062,\n",
       " 0.06329657882452011,\n",
       " 0.03467721864581108,\n",
       " 0.046473488211631775,\n",
       " 0.09790610522031784,\n",
       " -0.00663550291210413,\n",
       " 0.02520712837576866,\n",
       " -0.07798824459314346,\n",
       " 0.0169264767318964,\n",
       " -0.000945797364693135,\n",
       " 0.022471921518445015,\n",
       " -0.038253191858530045,\n",
       " 0.09570474177598953,\n",
       " -0.005350803025066853,\n",
       " 0.010469110682606697,\n",
       " -0.11524055153131485,\n",
       " -0.013262521475553513,\n",
       " -0.010709455236792564,\n",
       " -0.08311725407838821,\n",
       " 0.07327353954315186,\n",
       " 0.04939225688576698,\n",
       " -0.008994322270154953,\n",
       " -0.09584552049636841,\n",
       " 3.3661485617505796e-33,\n",
       " 0.12493184208869934,\n",
       " 0.01934972032904625,\n",
       " -0.05822571739554405,\n",
       " -0.03598826378583908,\n",
       " -0.05074676498770714,\n",
       " -0.04566238448023796,\n",
       " -0.08260336518287659,\n",
       " 0.1481948047876358,\n",
       " -0.08842118829488754,\n",
       " 0.06027443706989288,\n",
       " 0.05103015899658203,\n",
       " 0.01030314713716507,\n",
       " 0.14121422171592712,\n",
       " 0.03081384487450123,\n",
       " 0.061033159494400024,\n",
       " -0.052851270884275436,\n",
       " 0.1366489678621292,\n",
       " 0.00918989721685648,\n",
       " -0.01732518896460533,\n",
       " -0.012848555110394955,\n",
       " -0.007995282299816608,\n",
       " -0.0509800985455513,\n",
       " -0.05235064774751663,\n",
       " 0.007593012880533934,\n",
       " -0.015166307799518108,\n",
       " 0.01696030981838703,\n",
       " 0.021270520985126495,\n",
       " 0.020558107644319534,\n",
       " -0.12002813816070557,\n",
       " 0.014461833983659744,\n",
       " 0.02675991877913475,\n",
       " 0.025330696254968643,\n",
       " -0.0427546352148056,\n",
       " 0.006768387276679277,\n",
       " -0.01445858459919691,\n",
       " 0.04526195675134659,\n",
       " -0.09147648513317108,\n",
       " -0.019439145922660828,\n",
       " -0.017833467572927475,\n",
       " -0.05491018295288086,\n",
       " -0.052641112357378006,\n",
       " -0.010459048673510551,\n",
       " -0.052016086876392365,\n",
       " 0.020891955122351646,\n",
       " -0.07997036725282669,\n",
       " -0.012111340649425983,\n",
       " -0.05773142725229263,\n",
       " 0.023178234696388245,\n",
       " -0.008031732402741909,\n",
       " -0.02598930336534977,\n",
       " -0.07995671033859253,\n",
       " -0.020728832110762596,\n",
       " 0.048817697912454605,\n",
       " -0.020389137789607048,\n",
       " -0.04917657747864723,\n",
       " 0.014159622602164745,\n",
       " -0.06362202018499374,\n",
       " -0.007807393092662096,\n",
       " 0.01643155701458454,\n",
       " -0.0256824791431427,\n",
       " 0.013381040655076504,\n",
       " 0.026248741894960403,\n",
       " 0.009978413581848145,\n",
       " 0.06322886794805527,\n",
       " 0.002672201255336404,\n",
       " -0.006582767236977816,\n",
       " 0.01663188263773918,\n",
       " 0.03236646577715874,\n",
       " 0.03794245794415474,\n",
       " -0.036376070231199265,\n",
       " -0.006910930387675762,\n",
       " 0.0001596928050275892,\n",
       " -0.0016335808904841542,\n",
       " -0.02727821283042431,\n",
       " -0.02803807333111763,\n",
       " 0.049681417644023895,\n",
       " -0.028867173939943314,\n",
       " -0.0024180689360946417,\n",
       " 0.014774908311665058,\n",
       " 0.009764534421265125,\n",
       " 0.005797638092190027,\n",
       " 0.013486160896718502,\n",
       " 0.0055678957141935825,\n",
       " 0.03722710534930229,\n",
       " 0.007232527248561382,\n",
       " 0.04015626385807991,\n",
       " 0.08150326460599899,\n",
       " 0.07199167460203171,\n",
       " -0.013056126423180103,\n",
       " -0.0428820475935936,\n",
       " -0.01101123820990324,\n",
       " 0.004897820297628641,\n",
       " -0.009229730814695358,\n",
       " 0.035191506147384644,\n",
       " -0.05103502422571182,\n",
       " -1.571437557856825e-08,\n",
       " -0.08862441033124924,\n",
       " 0.02390925958752632,\n",
       " -0.01623876392841339,\n",
       " 0.031700510531663895,\n",
       " 0.027284247800707817,\n",
       " 0.05246882885694504,\n",
       " -0.047070957720279694,\n",
       " -0.058847445994615555,\n",
       " -0.06320822983980179,\n",
       " 0.04088849574327469,\n",
       " 0.04982800409197807,\n",
       " 0.10655171424150467,\n",
       " -0.07450230419635773,\n",
       " -0.012495421804487705,\n",
       " 0.01837071217596531,\n",
       " 0.03947412595152855,\n",
       " -0.024797886610031128,\n",
       " 0.014516262337565422,\n",
       " -0.03706921637058258,\n",
       " 0.02001572772860527,\n",
       " -4.85817035951186e-05,\n",
       " 0.00986657664179802,\n",
       " 0.024838753044605255,\n",
       " -0.05245814099907875,\n",
       " 0.029314178973436356,\n",
       " -0.08719190955162048,\n",
       " -0.01449968758970499,\n",
       " 0.026019077748060226,\n",
       " -0.01874636672437191,\n",
       " -0.07620512694120407,\n",
       " 0.03504333272576332,\n",
       " 0.10363949835300446,\n",
       " -0.028050510212779045,\n",
       " 0.012718182988464832,\n",
       " -0.07632549107074738,\n",
       " -0.01865232177078724,\n",
       " 0.02497672848403454,\n",
       " 0.0814453512430191,\n",
       " 0.06875883787870407,\n",
       " -0.0640566498041153,\n",
       " -0.08389385789632797,\n",
       " 0.06136231869459152,\n",
       " -0.033545564860105515,\n",
       " -0.10615336894989014,\n",
       " -0.040080588310956955,\n",
       " 0.032530225813388824,\n",
       " 0.07662483304738998,\n",
       " -0.0730162113904953,\n",
       " 0.00033755265758372843,\n",
       " -0.040871646255254745,\n",
       " -0.0757884755730629,\n",
       " 0.027527665719389915,\n",
       " 0.07462543249130249,\n",
       " 0.01771726831793785,\n",
       " 0.09121846407651901,\n",
       " 0.11022016406059265,\n",
       " 0.0005697731394320726,\n",
       " 0.05146336182951927,\n",
       " -0.014551310800015926,\n",
       " 0.03323203697800636,\n",
       " 0.023792240768671036,\n",
       " -0.02288980595767498,\n",
       " 0.038937538862228394,\n",
       " 0.030206844210624695]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "742e1790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "902c1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "# OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a72ba266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"medcare-medchatbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"medcare-medchatbot-7sq9qvt.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Install pinecone-client module\n",
    "# %pip install pinecone-client\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medcare-medchatbot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,  # The dimension of the embeddings\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "185c9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> pcsk_3TEqLd_KSZRqHyDw9phBUsmMLmUzzghGoK8k21oiY2zd9Ls7PKM4hPUU4ew9aUiP6JdQBT\n",
      "<class 'str'> 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\n"
     ]
    }
   ],
   "source": [
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "print(type(PINECONE_API_KEY), PINECONE_API_KEY)\n",
    "# print(type(OPENAI_API_KEY), OPENAI_API_KEY)\n",
    "print(type(GROQ_API_KEY), GROQ_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e179f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "# os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be921743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install langchain-pinecone if not already installed\n",
    "# %pip install langchain-pinecone\n",
    "\n",
    "# embed each chunk and upsert the embeddings into your pinecone index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98e200b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing Index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "#Embed each chunk and upsert the embeddings into your pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55432181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x23c899abd90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3be6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84261c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrived_docs = retriever.invoke(\"What is the best way to treat a headache?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f992585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d44b497f-8b0b-4d52-b9da-f3a0855d625f', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 52.0, 'page_label': '53', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Gale Encyclopedia of Medicine Vol. 1 (A-B).pdf', 'total_pages': 637.0}, page_content='with the thumb or finger, for two minutes on each arm.\\n• For headaches, sinus congestion, and tension, locate the\\n“GB20” points at the base of the skull in the back of the\\nhead, just behind the bones in back of the ears. Disperse\\nthese points for two minutes with the fingers or thumbs.\\nAlso find the “yintang” point, which is in the middle of\\nthe forehead between the eyebrows. Disperse it with\\ngentle pressure for two minutes to clear the mind and to\\nrelieve headaches.\\nPrecautions'),\n",
       " Document(id='9c5497d5-39a7-47a7-8735-948d5aecb087', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 303.0, 'page_label': '304', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Gale Encyclopedia of Medicine Vol. 1 (A-B).pdf', 'total_pages': 637.0}, page_content='General dosage advice\\nAlways take antimigraine drugs exactly as directed.\\nNever take larger or more frequent doses, and do not take\\nthe drug for longer than directed.\\nIf possible, lie down and relax in a dark, quiet room\\nfor a few hours after taking the medicine.\\nPrecautions\\nThese drugs should be used only to treat the type of\\nheadache for which they were prescribed. Patients should\\nnot use them for other headaches, such as those caused\\nby stress or too much alcohol, unless directed to do so by'),\n",
       " Document(id='5b0ad6a2-c103-4fe0-a76e-812a8c178b53', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 304.0, 'page_label': '305', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Gale Encyclopedia of Medicine Vol. 1 (A-B).pdf', 'total_pages': 637.0}, page_content='flashing lights, that some people have 10-30 min-\\nutes before a migraine attack.\\nInflammation —Pain, redness, swelling, and heat\\nthat usually develop in response to injury or illness.\\nTreatment You Need. New York, NY: The Guilford Press,\\n1995.\\nORGANIZATIONS\\nAmerican Council for Headache Education (ACHE). 19 Man-\\ntua Road, Mt. Royal, NJ 08061. (800) 255-2243. <http://\\nwww.achenet.org>.\\nNational Headache Foundation. 428 W. St. James Place, Chica-\\ngo, IL 60614. (800) 843-2256. <http://www.head')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "595afcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import OpenAI\n",
    "# llm = OpenAI(temperature=0.4, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a961c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"you are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Do not try to make up an answer. \"\n",
    "    \"Use three sentences maximum and keep the answer concise. \"\n",
    "    \"\\n\\n\"\n",
    "    \"Context: {context}\\n\\n\"    \n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf96b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50916330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms.openai import OpenAI\n",
    "# llm = OpenAI(temperature=0.4, max_tokens=500, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0.4,\n",
    "    model_name=\"llama3-70b-8192\",  # or \"llama3-8b-8192\"\n",
    "    groq_api_key=os.environ[\"GROQ_API_KEY\"]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e72bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "print(api_key)  # <-- Check if it's printing something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e590370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: **What is Acne?**\n",
      "\n",
      "Acne is a common skin condition that occurs when the pores on the skin become clogged with oil, dead skin cells, and bacteria. It can cause a range of symptoms, including:\n",
      "\n",
      "* Pimples (also known as zits or spots)\n",
      "* Blackheads\n",
      "* Whiteheads\n",
      "* Cysts\n",
      "* Nodules\n",
      "* Redness and inflammation\n",
      "\n",
      "Acne can appear on various parts of the body, including the face, neck, back, chest, and shoulders. It is most common during puberty, but can also occur in adults.\n",
      "\n",
      "**Causes of Acne:**\n",
      "\n",
      "The exact cause of acne is still not fully understood, but several factors are known to contribute to its development, including:\n",
      "\n",
      "1. **Hormonal changes**: Fluctuations in hormone levels, such as during puberty, menstruation, or pregnancy, can lead to increased oil production and clogged pores.\n",
      "2. **Oil production**: The skin's oil glands produce sebum, an oily substance that can clog pores and lead to acne.\n",
      "3. **Dead skin cells**: When dead skin cells are not shed properly, they can combine with oil and bacteria to clog pores.\n",
      "4. **Bacteria**: A type of bacteria called Propionibacterium acnes (P. acnes) is naturally found on the skin and can contribute to the development of acne.\n",
      "5. **Genetics**: Family history can play a role in the development of acne.\n",
      "6. **Environment**: Exposure to pollution, humidity, and certain chemicals can contribute to acne.\n",
      "\n",
      "**Types of Acne:**\n",
      "\n",
      "There are several types of acne, including:\n",
      "\n",
      "1. **Mild acne**: Characterized by a few small pimples and minor inflammation.\n",
      "2. **Moderate acne**: More widespread and inflammatory, with larger pimples and possibly scarring.\n",
      "3. **Severe acne**: Large, painful cysts and nodules, which can lead to scarring and permanent damage.\n",
      "\n",
      "**Treatment Options:**\n",
      "\n",
      "While there is no cure for acne, various treatments are available to help manage symptoms and prevent scarring. These include:\n",
      "\n",
      "1. **Topical creams and gels**: Apply directly to the skin to reduce inflammation and kill bacteria.\n",
      "2. **Oral antibiotics**: Taken by mouth to reduce bacteria and inflammation.\n",
      "3. **Hormonal therapies**: Used to regulate hormonal imbalances and reduce oil production.\n",
      "4. **Blue light therapy**: A non-invasive treatment that uses light to kill bacteria and reduce inflammation.\n",
      "5. **Extraction and drainage**: A surgical procedure to remove large cysts and nodules.\n",
      "\n",
      "It's essential to consult a dermatologist for proper diagnosis and treatment, as they can help determine the best course of treatment for your specific type of acne.\n"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "# import os\n",
    "\n",
    "# client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# from anthropic import Anthropic\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# response = client.messages.create(\n",
    "#     model=\"claude-3-sonnet-20240229\",\n",
    "#     max_tokens=500,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"What is Acne?\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(response.content[0].text)\n",
    "\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from groq import Groq\n",
    "\n",
    "# load_dotenv()\n",
    "# client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"mixtral-8x7b\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"What is Acne?\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# groq_chatbot.py\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "# Load .env file and read API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please check your .env file.\")\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "# Chat request using Mixtral-8x7B\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",  # ✅ Correct model name\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"What is Acne?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Bot:\", response.choices[0].message.content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "575a7a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a disorder in which the abnormal release of a particular chemical from the pituitary gland in the brain causes increased growth in bone and soft tissue, as well as a variety of other disturbances throughout the body.\n"
     ]
    }
   ],
   "source": [
    "# response = rag_chain.invoke({\"input\": \"What is Acne?\"})\n",
    "# print(response['answer']) \n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"What is the Acromegaly?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a42b96d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a disorder in which the abnormal release of a particular chemical from the pituitary gland in the brain causes increased growth in bone and soft tissue, as well as a variety of other disturbances throughout the body.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is the Acromegaly?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedChat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
